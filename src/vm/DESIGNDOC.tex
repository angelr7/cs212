            +---------------------------+
            |          CS 212           |
            | PROJECT 3: VIRTUAL MEMORY |
            |      DESIGN DOCUMENT      |
            +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.
Angel Ruiz <ar7@stanford.edu>
Pilli Cruz-De Jesus <pilli@stanford.edu>
Fabian Luna <luna1206@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

            PAGE TABLE MANAGEMENT
            =====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* This is our supplemental page struct, it keeps
track of all information needed to retrieve a page
of information in swap or file and write it to memory. */
struct page {
    /* In Memory */
    struct frame_entry *frame;
    void *physical_addr;

    /* In Disk */
    struct file *file;
    off_t file_ofs;
    size_t page_read_bytes;
    size_t page_zero_bytes;
    mapid_t mapid;

    /* In Swap*/
    int swap_slot;

    /* Everything */
    void *virtual_addr;
    struct hash_elem hash_elem;
    struct thread *process_reference;
    short memory_flag;    
    bool writable;
};

/* This member was added into the thread struct so that each 
   process can manage its own SPT. */
struct thread
{
    struct hash spt;
}

---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for accessing the data
>> stored in the SPT about a given page.
Our SPT is in the form of a hash table, and each one of its items is 
represented by our page struct. For this reason, all of our page logic
with the SPT uses functions like hash_insert and hash_find to access and 
interact with the stored page data. In our implementation, we only use two
functions to access the data stored about a given page: page_fetch and 
load_page. These functions fetch the page data from the SPT and load the 
page into the memory, respectively.

page_fetch is a rather simple function, and simply grabs the page 
reference from a given thread's SPT. We first begin by rounding down a 
user address to find the page entry that corresponds to that address. We
then declare a struct page variable, but only fill in the virtual 
address for that page, so that we can pass it into the hash_find function.
This function finds the hash_elem with the corresponding user address if 
it exists, and returns NULL if it doesn't. We then use the hash_entry call 
in order to convert the hash_elem that into a struct page and return it.

load_page first tries to find a page entry in the SPT for a given 
fault_addr. If the fault_addr returns NULL, we check to see if our stack
is trying to grow itself; if not, we return false, because there's no page
to load from the SPT. If we do have an address, however, we fetch the 
frame for that given user page; if the page has not yet had a 
physical_address assigned to it, we return false. In the event that there 
is a frame for that address, we then fetch that data, whether it is zeroed,
on swap, etc, and set that information in the page, along with its memory 
flag to indicate it's in memory. If there are any errors that we encounter
after we've fetched the frame, we make sure to free the frame before 
returning false.

>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?
To avoid any extra configuration with our codebase, we chose to exclusively 
access data through user virtual addresses. By avoiding any use of the 
actual physical address that a given virtual page is mapped to, we 
completely avoid dealing with data inconsistencies that may arise from 
holding that underlying kernel page. We have also not implemented file 
sharing at any point in time, so there are no other aliasing situations
that can arise in our ecosystem.

---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?
When we call get_frame, we get the new frame by accessing and modifying a
bitmap with the bitmap_scan_and_flip call. In order to avoid races in this
scenario, we have a bitmap_lock that is a static global that we define in 
page.c. This lock is initialized in the frame_table_init call, so we know 
that all threads will be able to access and use this lock as required. We 
use this lock when modifying the bitmap during a get_frame or free_frame 
call so that there are no read/write inconsistencies that may arise from 
races when freeing/getting frames.

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?
We used our page struct to represent our virtual-to-physical mappings. In
this struct, the virtual_addr, hash_elem, process_reference, memory_flag, 
and writeable boolean are always used. This allows us to manage the page 
and retrive information about it no matter where the kernel page for that 
user address is. In the event that the kernel page is in memory, swap, or 
on disk, we can simply check our memory_flag and do certain actions with
or on that page. Once checking this flag, we can then go on to use certain 
member variables that apply and can be used in each corresponding
situation.

               PAGING TO AND FROM DISK
               =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Frame entry structed used to fill the frame table 
contains frames physical address, virtual address,
process_thread, lock, and pinned boolean. */
struct frame_entry
{
    void *physical_address;         /* Physical address associated with this frame */
    void *virtual_address;          /* Virtual address associated with this frame */
    struct thread *process_thread;  /* Pointer to a process thread which owns this frame at this time */
    struct lock lock;               /* Lock */
    bool pinned;                    /* Bool to see if this frame is pinned */
};

static struct frame_entry **frame_table;    /* Array of frame_entry which makes up our frame table */
static size_t frame_table_size;             /* Frame Table Size */
static struct bitmap *used_map;             /* Bitmap which keeps track of which spaces in the frame_table are available */
static struct lock bitmap_lock;             /* Bitmap Lock */
static int cur_evict;                       /* Index to keep track of last eviction location in frame table */

static struct bitmap *used_map;         /* map of used swap slots */
static struct block *swap_block;        /* entire block on disk that makes up swap */
static int num_slots;                   /* number of slot in our swap */
static size_t sectors_per_page;         /* number of sectors in a page */
static struct lock swap_lock;           /* lock for swap */

/* esp stack pointer saved when page faulting for stack growth heuristic*/
struct thread
{
    void* esp;                  /* esp stack pointer */
}

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

 We utilized the clock algorithm to manage eviction. The very first time
 we evict we begin by looking at the start of our frame table array and iterate
 through it. If the frame is pinned we skip over it. We then checked that frames
 accessed bit, ff accessed is true, we set it to false and continue. If
 accessed is false we evict that page. The next time we evict we continue
 at the page after the one previously evicted. Once we reach the end we jump
 back to the beginning like a clock. We evict that frame depending on the
 type of information it holds (originally from a file vs mmaped) and return
 the index of the evicted frame, so that the evicted frame entry can be used.


>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?


When process P needs to get a frame and ends up having to evict a frame that
is currently occupied by process Q, we first clear the page in process Q's
page directory so that it is no longer able to access that page's virtual
addresses without page faulting. We then use the page entry from process Q's
supplemental page table to determine how to evict the data from process Q.
If we are dealing with a read only page from a file, we simply set the Q's
page table entry memory flag to IN_DISK and do not execute any writes. If
the page is writable and not memory mapped, we write the data to a swap slot
and make sure to set the memory flag to IN_SWAP and set the page entries
swap slot to the slot we wrote to. If it is from a memory mapped file, we
write back to the file on disk and set the memory flag to IN_DISK. In all
cases, we make sure to update the memory flag and set the page entry's
physical address to NULL. Keeping track of all of this information allows
us to correctly load the data back in when page faulting on the evicted page
again. Once we have successfully evicted the page, we are able to update the
frame table entry to now belong to the new process P and its page's virtual
address. When the get_frame function returns to process P, it is able to use
the returned frame_entry struct to update its own supplemental page table
entry with frame that it is occupying and the frame's physical address. We
also update the entries memory flag to reflect that it is now in memory.

Outside of evictions, any time a frame is assigned to a supplemental page
entry we update the fields of the page entry accorindingly to reflect this
as well as the frame entry in the frame table. We also set create the mapping
in the thread's page directory to prevent page faults on this now mapped page.
When we free a page and no longer use a frame, we update both the page entry
to no longer use the frame's data and the frame table to mark that frame as 
free by setting the processs thread and virtual address thread fields to NULL.
When a process calls get_frame and is assigned a frame without having to evict,
it can be sure that the page table entries of any other processes will be 
up to date and no longer using the information of the same frame. The process
can safely map the virtual address to the frames physical address in its page
directory and write its page data into the physical page. We update the fields
of the page entry to reflect that it is now in memory.

>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

In order to determine whether or not a page fault should cause the stack
to be extended we created a new esp member variable for the thread struct.
Whenever an interrupt handler is called and we see that we will be handling
a page fault, we save the interrupt frame's esp pointer to the thread struct.
This way, we have the correct esp pointer that we can reference in our
load_page function. Within the load_page function, if no entry for the fault
address exists in the supplemental page table then we may be in a situation
where we need to extend the stack. We compare the fault address to the
thread's esp pointer variable, and if the fault address is equivalent to the
esp pointer or within 32 bytes below the stack pointer then we know that this
is a valid stack access and can extend the stack by creating a supplemental
page entry for it and zeroing out the stack page we are creating in memory.
Our heuristic checks that esp - 32 <= fault address <= esp because the 
PUSHA instruction checks access permissions before adjusting the stack pointer
and pushes 32 bytes at once, so we have this lower bound of esp - 32 that
we have to take into account. This is the most bytes that can be pushed by an
instruction like that so we can be sure that esp - 32 is truly the lower bound.


---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

We know from lecture that for deadlock to be possible you must have: limited 
access, no preemption, multiple independent requests, and circularity in 
graph of requests. 

Our synchronization design removes circularity in the graph of requests.
We have two primary locking methods when it comes to the frames. We have
fine grained locks for each frame so that no one frame can be accessed
or editted at the same time. We also have a bitmap lock which ensures that
no two processes can evict at the same time and that parallel get_frame
or remove_frame calls can not happen. 

For swap we utilize a swap lock for two purposes. One is to ensure that
swap_add and swap_remove calls can not happen at the same time. And second
to ensure that simultaneous swap_add or simultaneous swap_remove calls
are not possible. 

For both swap and frame we keep the ordering consistent
to ensure that out of order locking issues do not occur. This
is especially relevant with the global frame table lock and the
fine grained frame_entry locks. To avoid circular deadlock we ensure
that we always lock using the global bitmap_lock first and then
follow it with the frame_entry lock. Swap locks are always internal to
swap function calls and so ordering is not relevant in this case. 
The filesys_lock is used by itself similiar to the swap lock, but is
always called in the correct ordering to avoid circularity.

>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

In the event that P is evicting and Q page faults on the page being evicted,
Q will call our load_page function which calls get_frame() to get the page
from the supplemental page table at the address which we faulted at. 
Our get_frame() call is locked using our bitmap_lock and will not fetch 
any frame until the bitmap_lock is released. Whenever we call evict_algo 
it is protected using the bitmap_lock as well. This ensures that process 
Q will not be able to access or modify any frame until after P completes 
the eviction algorithm. This ensures that a race is not possible
in the situation described.

>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

To read in a frame a process must call get_frame. In our get_frame call
we pin that frame to ensure that it can not be evicted. In the locations
where the frame is getting read in we do not unpin until the read is
completed. This will ensure that the eviction algorithm will always
skip over pages which are being read because they are currently being
pinned. 

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

In this situation we do NOT utilize page faulting. Our verify pointer call
pins all the pages being accessed by that pointer. This in essence sets the
frame pinned boolean to true for these frames. This ensures that any eviction
will skip over any pinned pages so that we do not page fault in the kernel.
In the verify pointer call instead of page faulting in the kernel we load 
in the information from the supplemental page table and move forward with 
the system call to avoid the situation of page faulting while in the
kernel. 

This ensures that if in this situation where we are working with an invalid
virtual address we first check that each page being in that buffer
is in the supplemental page  table. If it is not in the SPT we know 
that it is an invalid virtual address and gracefully handle the
attempted accesses by calling our exit_handler(-1). 


---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

We utilize a combination of larger locks such as our bitmap_lock and swap_lock
as well as fine grained locks such as frame_entry locks to lock in differing
situations and to lock large chunks of memory or high traffic areas 
for the minimum time possible. 

We felt that solely having large locks would limit parallelism in many ways.
At the same time having solely fine grained locks would allow for multiple
processes to call functions such as get_frame, evict_algo, swap_remove, 
or swap_add simultaneously, which would introduce many dangerous race
conditions. 

In swap we use one larger swap lock, we did this because it was crucial that
no simultaneous calls would be adding at the same time, removing at the same
time or some combination of the two. If this was possible we would have a 
multitude of race conditions, when trying to read and write to the block
at the same time. Another option would have been fine grained locks for
each sector but it felt like it would not add in very much parallelism since
we would need to be locking our bitmap with a global lock every time 
regardless, and we would need to lock the entire block on block_read and
block_write calls.

For our frame table we used a global bitmap_lock as well as fine grained
locks for every frame entry. There were many instances in which we would
need to work with just one frame_entry but locking the entire frame_table
seemed unreasonable and would reduce parallelism drastically. Because of
this we used fine grained locks as much as possible, but in cases where
the frame table should not be editted at the same time such as get_frame,
remove_frame, and evict_algo we utilize the global bitmap lock to ensure
that eviction can not be parallel with adding and removing frames. 

We utilize the global filysys_lock to protect from any simultaneous system
calls such as filesys_read, filesys_write, etc. 

             MEMORY MAPPED FILES
             ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

This struct is used to keep track of mapid mappings created from mmap calls.
    struct mapid_elem
    {
        mapid_t mapid;
        int fd;
        void *start_addr;
        struct list_elem elem;
    };

The mapid_list thread member variable keeps track of all of the mapid mappings
created from a process's calls to mmap. The cur_mapid variable is the current
id to give out to the next call of mmap.
    struct thread
    {
       struct list mapid_list; 
       int cur_mapid; 
    }

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

We create entries in our supplemental page table for each page of a memory
mapped file. In the supplemental page table entries for these files,
we keep track of information about the file that we will need to
read from and write to the file on disk, such as the pointer to the file
struct and the offset within the file we want to read and write to, along
with the mapid for the mmap mapping. These spt entries are always writable
and look similar to non memory mapped file entries, except non memory mapped
entries have a mapid of NO_MAPID. This allows us to determine whether an 
entry in the spt belongs to a memory mapped file.

During the page fault and eviction processes, we are able to use the
information stored in the spt entries to know when we are dealing with
a memory mapped file's page. When page faulting, we are able to check the
page's memory flag to see if the page is currently on disk when we are
loading it in. If it is on disk, we know that it comes from a file and we
are able to read page into physical memory from the file on disk. If we
have a memory flag indicating that the page is on the swap partition, we
are able to read that page back in to memory from the swap slot. During 
eviction, we are able to use the mapid page entry member variable to
determine if we are evicting a memory mapped file. If that is the case,
we write that page's contents back to the file on disk. If the page entry's
mapid is equal to the NO_MAPID constant, then we proceed by determing if
we need to evict the page to the swap partition if the page belongs to an
executable but is writable, or is simple a stack page. Else, if the page
belongs to a file and is read-only, we are able to simply zero out the page
since we can bring in the unchanged file from disk when we page fault on
this page again.

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

Given the mapping's starting address as a parameter, we first check that it
is valid (is multiple of PGSIZE and non-NULL). If it is valid, we proceed by
checking is the new mapping overlaps any existing segment. We use the file's 
length, obtained by calling file_length on the file we are mapping, and
calculate the total number of pages that the file will need to take up in its 
mapping. We loop through all the pages that the mapping would use beginning
from the given starting address parameter and check if
an entry for that page already exists in the supplemental page table. If we
ever encounter an already mapped page, we know that there is overlap and
fail mmap. If we detect that there is no overlap, we are able to create page
entries for all the pages we just looped over during our overlap check.

---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

Because of these similarities, we are able to treat both mmap mappings
and data demand-paged from the executables the same when page faulting.
When we page fault, we simply check if the data we need to bring in is
on disk, which is true in both of these situation, and simple read in
the data from the file on disk utilizing the same page entry member
variables for both. The differences between the page entries for
these different situations are the mapid value and writable bool. For 
memory mapped files, all page entries will have a valid mapid value and
writable will always be true. For data demand-paged from executables, 
the mapid value will be NO_MAPID and the writable bool depends on what
section of data it pertains too (code vs. data). This is important for
page eviction and the freeing of pages upon process exit. If we are 
evicting or freeing a page with a valid mapid, we write the data from
memory back to the file on disk. If there is no valid mapid, then we 
use the writable flag to know how to handle an eviction. If the page is
writable, we write the page to a swap slot and read it back in from the
swap slot when paged back in. If not writable, no writes to disk need to be
made and we can read the data back in from the file system when it is paged
back in. When simple freeing and not evicting page entries with no mapid,
we never write back to disk. We are not able to share much of the code
when evicting or freeing in these two situations because we must write to
different partitions or not write depending on the situation. However,
as explained before, we are able to share much of the code for these two
situations when reading in from files (excluding data evicted to swap).

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?

            +--------------------+
            |        CS 212      |
            | PROJECT 1: THREADS |
            |   DESIGN DOCUMENT  |
            +--------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Pilli Cruz-De Jesus <pilli@stanford.edu>
Angel Ruiz <ar7@stanford.edu>
Fabian Luna <luna1206@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
>>
static struct list tick_list;
    The tick list holds all of the sleep durations for the blocked 
    threads in ascending order so our tick interrupt can wake 
    them up appropriately.

struct tick_list_item {
    int64_t ticks;
    struct thread *thread_ref;
    struct list_elem elem;
};
    This struct represents an item in the tick list. It has a
    list elem which is used to manage its position, a reference to a 
    sleeping thread, and a tick value for when the thread should wake up.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.
When a function calls timer_sleep() we first disable interrupts. Then, we
check for a valid interval (i.e > 0) and create a new tick_list_item 
using the current running thread and the tick value. We then insert our 
tick_list_item into tick_list, ordering by ascending tick duration. We then 
block the thread. 

The timer_interrupt handler at every system tick loops through tick_list
and checks if the number of OS ticks is greater than each item's sleep duration. 
We then unblock the thread and remove its entry in the tick list if needed.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
When we find the first duration that has not elapsed we stop searching. 
We also carefully monitored our allocation of stack variables so that we
do not unnecessarily use memory and increase runtime. 


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?
Race conditions are avoided because upon a timer interrupt, all threads
whose duration has passed will be woken up. Since the tick_list is ordered,
all of the threads will be woken up in the correct order as well. Unblocking 
all of the threads in order also allows the simple scheduler to maintain the 
correct thread ordering. 

When we disable interrupts we prevent other threads from inconsistently modifying 
shared variables such as tick_list. We also avoid time discrepencies from calculations
using the global ticks variable.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
When this situation occurs the interrupt would not be handled because 
for most of timer_sleep() interupts are disabled. 

If an interrupt were to occur before we disabled them, our if condition 
checks to make sure that the interval has not passed when the original 
thread is pushed back on the CPU.


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
When we initially approached the problem, we considered using only condition variables to 
manage sleeping threads. This quickly became a problem, mainly because it is forbidden for 
interrupt handlers to acquire locks. For this reason, our team decided to take a simpler 
approach by creating a global tick_list and disabling interrupts. This was a much better 
approach because it requires less code, and also allowed us to unblock sleeping threads in the 
timer interrupt handler. By unblocking sleeping threads inside of this interrupt, we make sure 
that we consistently wake up threads when necessary, since we check for elapsed durations upon
every OS tick.


             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
{
  struct lock *lock_acquiring;
  struct lock *lock_releasing;
  struct list locks_holding;
};
    The added lock_acquiring and lock_releasing lock pointers keeps track of when
    a thread is in the middle of acquiring and releasing a lock. The locks_holding
    list keeps track of all the locks a thread is holding for the purposes of
    calculating priority donation values.

struct lock
{
  struct list_elem elem;
};
    This added list_elem is used to add locks to threads' locks_holding lists.


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

In order to track priority donations, each thread keeps a list of all the locks
it is currently holding. When we want to get the priority of the thread, we take
the maximum between the threads priority and the maximum of the donated priorities
coming from the locks it is holding. Obtain the maximum of the donated priorities
by looping through all the locks the thread is holding and finding the maximum
priority of each locks waiters. This algorithm recursively calls get_thread_priority()
in order to calculate the priorities of the threads that are donating their priorities
to the original thread whose priority we are getting.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
When choosing a thread to wake up, we use the list_max function to choose
the highest priority thread from the lists. Our less than function used
by list_max calls get_thread_priority to retrieve a threads priority and
returns the first thread with the maximum priority found in the list.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
Within the lock_acquire function before calling sema_down, we set the
thread's lock_aquiring member to point to the lock. Within the sema_down
function, the thread will add itself to the lock semaphore's waiters list
and block. When the thread is able to continue within sema_down, it will 
check if it is currently aquiring a lock by checking if the threads 
lock_acquiring member is not NULL. If it is aquiring a lock, then we add 
the lock we are acquiring to the thread's locks_holding list and set 
lock_acquiring to NULL to signify that we are done with the process of 
acquiring this lock and exit sema_down.

We handle nested donations by adding acquired locks to each thread's locks_holding
list. When retrieving the thread's priority, we utilize the locks_holding list 
to calculated the thread's donated priority by looping through the list and 
getting the donated priority coming from the waiters of those locks. In the nested 
case, we also go through the waiting threads' locks_holding lists to retrieve 
their nested donated priorities.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
In the list_release function we set the thread's lock_releasing member to point to
the lock that the thread is currently holding, prior to calling sema_up.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

This is assuming that the PRI_MAX is equal to 63.

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0     0   0   0   63  61  59     A
 4     4   0   0   62  61  59     A
 8     8   0   0   61  61  59     B
12     8   4   0   61  60  59     A
16     12  4   0   60  60  59     B
20     12  8   0   60  59  59     A
24     16  8   0   59  59  59     C 
28     16  8   4   59  59  58     B
32     16  12  4   59  58  58     A
36     20  12  4   58  58  58     C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

The problem above does not specify the behavior of the scheduler when two 
or more threads have the same priority. In this case, I chose to run threads
with the same priority on a round-robin basis. This is exactly what we chose
to do in our real approach as well. 

When it comes to calculating recent_cpu, priority, and load_avg, the order is
not explicity specified in the project documentation. We first increment recent_cpu, 
and then calculate the priority afterwards if necessary (we are at the thread's fourth 
tick on the CPU). Although it isn't relevant for the problem above, we also must follow
this process on the OS's 100th tick:
    -- Increment recent_cpu for running thread
    -- Calculate load_avg. This is done once, since load_avg isn't thread specific.
    -- Recalculate recent_cpu and priority for all threads, respectively. 

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?
The advantages of our design lies in the memory optimizations that we made
in our program. For example, we use thread_foreach to streamline the operations
that we make when updating all threads. In addition, we supply a recent_cpu_changed
boolean to the thread struct, which allows us to determine if we need to recalculate 
its priority in a more lightweight manner (i.e. compared to a list).
The cons of our design mostly pertains to the way that we handle recalculations related
to thread priority. Although we tried to optimize using thread_foreach, we would be able
to further optimize our search and updating process if we used a list of threads whose 
recent_cpu was recalucated. If we were to have extra time, we would most likely spend it 
trying to optmize this process, since we unnecessarily loop over all threads by using
thread_foreach.


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We initially tried an approach without a fixed-point file and calculated all 
the math in the calulate_load_avg, calculate_priority, and calculate_recent_cpu
functions. We were running into bugs and found that creating a fixed point file
made our thread code more readable, made it faster, and left less room for error
in our calculations between fixed points. Also, we used the set of functions in
fixed-point.c because there were other places where fixed pointer arithmetic was
needed such as increamenting recent_cpu every tick and fp_to_int_round_nearest
which was used in functions thread_get_load_avg and thread_get_recent_cpu. The
multiple use of these functions made it a good candidate to put in a seperate file
with function calls to not be rewritten. 

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
